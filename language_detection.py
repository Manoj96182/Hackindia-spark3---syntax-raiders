# -*- coding: utf-8 -*-
"""language_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zyoEn_6k3m3QH_LeJJY-gcA0hNNgsy9y

STEP 1: Importing the all libraries
"""

import pandas as pd
import numpy as np

"""STEP 2: importing the dataset from the kaggle or any other websites to predict based on the these dataset only"""

ld=pd.read_csv('/content/Language Detection.csv')

"""STEP 3:Summarize the dataset"""

ld.head()

ld.tail()

ld.describe()

ld.info()

ld.columns

ld.isnull().sum()

ld["Language"].value_counts()

"""STEP 4: identify the inputs to provide by the user  and output"""

y=ld['Language']
x=ld[['Text']]
y.shape
x.shape

"""STEP 5: Split the data set into train and test"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.75,random_state=42)
x_train

"""STEP 6 :select the model"""

from sklearn.naive_bayes import MultinomialNB
model=MultinomialNB()

"""STEP 7: Converting the text into numerical"""

from sklearn.feature_extraction.text import CountVectorizer

# Create a CountVectorizer object to convert text to numerical features
vectorizer = CountVectorizer()

# Fit the vectorizer on the training data and transform both training and testing data
x_train_vec = vectorizer.fit_transform(x_train['Text'])
x_test_vec = vectorizer.transform(x_test['Text'])

# Now fit the model on the vectorized data
model.fit(x_train_vec, y_train)

"""STEP 8: Finding the accuracy"""

model.score(x_train_vec,y_train)

user=input("Enter a Text: ")
data=vectorizer.transform([user]).toarray()
output=model.predict(data)
print(output)

